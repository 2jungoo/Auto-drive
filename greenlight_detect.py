#!/usr/bin/env python3

import rclpy
from rclpy.node import Node
from rclpy.qos import QoSProfile, ReliabilityPolicy
from sensor_msgs.msg import CompressedImage, LaserScan
from geometry_msgs.msg import Twist
import cv2
import numpy as np
import threading
import time
import socket
import math
from http.server import BaseHTTPRequestHandler, HTTPServer
from enum import Enum

qos_profile = QoSProfile(depth=10)
qos_profile.reliability = ReliabilityPolicy.BEST_EFFORT

class DriveMode(Enum):
    WAITING_FOR_GREEN = "WAITING_FOR_GREEN"
    RUBBERCON_AVOIDANCE = "RUBBERCON_AVOID"
    LANE_FOLLOWING = "LANE_FOLLOW"
    EMERGENCY_STOP = "EMERGENCY_STOP"

class WebViewer(BaseHTTPRequestHandler):
    def __init__(self, autoracer_node, *args, **kwargs):
        self.autoracer = autoracer_node
        super().__init__(*args, **kwargs)

    def do_GET(self):
        if self.path == '/':
            self.send_response(200)
            self.send_header('Content-Type', 'text/html')
            self.end_headers()
            html = f"""
            <html>
            <head>
                <title>ğŸš— Autoracer 2025 Contest</title>
                <style>
                    body {{ background: linear-gradient(135deg, #1e1e1e, #000000); color: #f0f0f0; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; margin: 0; padding: 20px; }}
                    .container {{ max-width: 900px; margin: auto; background-color: #2a2a2a; padding: 20px; border-radius: 10px; box-shadow: 0 0 15px rgba(0,0,0,0.5); }}
                    h1, h2 {{ color: #4CAF50; border-bottom: 2px solid #4CAF50; padding-bottom: 5px; }}
                    .stats-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 20px; margin-top: 20px; }}
                    .stat-box {{ background-color: #333; padding: 15px; border-radius: 8px; text-align: center; }}
                    .stat-value {{ font-size: 2em; font-weight: bold; color: #f0f0f0; }}
                    .stat-label {{ color: #aaa; font-size: 0.9em; margin-top: 5px; }}
                    #image-feed {{ margin-top: 20px; text-align: center; border: 2px solid #555; border-radius: 8px; }}
                </style>
            </head>
            <body>
                <div class="container">
                    <h1>ğŸš¦ Traffic Light Detection Dashboard</h1>
                    <div class="stats-grid">
                        <div class="stat-box"><div class="stat-value" id="current_mode">N/A</div><div class="stat-label">Current Mode</div></div>
                        <div class="stat-box"><div class="stat-value" id="traffic_light_status">N/A</div><div class="stat-label">Traffic Light</div></div>
                        <div class="stat-box"><div class="stat-value" id="confidence">N/A</div><div class="stat-label">Confidence</div></div>
                        <div class="stat-box"><div class="stat-value" id="fps">N/A</div><div class="stat-label">FPS</div></div>
                    </div>
                    <h2>Camera Feed</h2>
                    <img id="image-feed" src="/image_feed" alt="Camera Feed" width="100%">
                </div>
                <script>
                    function fetchStats() {{
                        fetch('/stats')
                            .then(response => response.json())
                            .then(data => {{
                                document.getElementById('current_mode').innerText = data.current_mode;
                                document.getElementById('traffic_light_status').innerText = data.traffic_light_status;
                                document.getElementById('confidence').innerText = data.confidence + '%';
                                document.getElementById('fps').innerText = data.fps;
                            }});
                    }}
                    setInterval(fetchStats, 500);
                </script>
            </body>
            </html>
            """
            self.wfile.write(html.encode('utf-8'))
        elif self.path == '/image_feed':
            if self.autoracer.last_image is not None:
                self.send_response(200)
                self.send_header('Content-Type', 'image/jpeg')
                self.send_header('Content-Length', str(len(self.autoracer.last_image)))
                self.end_headers()
                self.wfile.write(self.autoracer.last_image)
            else:
                self.send_response(404)
                self.end_headers()
        elif self.path == '/stats':
            self.send_response(200)
            self.send_header('Content-Type', 'application/json')
            self.end_headers()
            stats = self.autoracer.get_stats()
            self.wfile.write(bytes(str(stats).replace("'", '"'), 'utf-8'))
        else:
            self.send_response(404)
            self.end_headers()

class TrafficLightDetector(Node):
    def __init__(self):
        super().__init__('traffic_light_detector')
        self.qos_profile = QoSProfile(depth=10)
        self.qos_profile.reliability = ReliabilityPolicy.BEST_EFFORT

        # ROS2 êµ¬ë…ì
        self.image_subscriber = self.create_subscription(
            CompressedImage,
            '/image_raw/compressed',
            self.image_callback,
            self.qos_profile
        )
        
        # ì œì–´ ë°œí–‰ì (ì‹¤ì œë¡œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
        self.cmd_vel_publisher = self.create_publisher(Twist, '/cmd_vel', 10)

        # ìƒíƒœ ë³€ìˆ˜
        self.last_image = None
        self.last_processed_image = None
        self.detected_color = "NONE"
        self.confidence = 0.0
        self.frame_count = 0
        self.fps = 0.0
        self.last_time = time.time()
        
        # ì‹ í˜¸ë“± ê²€ì¶œ ìƒíƒœ
        self.green_detected = False
        self.consecutive_green_frames = 0
        self.red_detected = False
        self.orange_detected = False
        
        # í˜„ì¬ ëª¨ë“œ
        self.current_mode = DriveMode.WAITING_FOR_GREEN

        # OpenCV ìœˆë„ìš° í‘œì‹œë¥¼ ìœ„í•œ ìŠ¤ë ˆë“œ
        self.display_thread = threading.Thread(target=self.display_loop, daemon=True)
        self.display_thread.start()

        # ì›¹ ëŒ€ì‹œë³´ë“œ ì„œë²„ ì‹œì‘
        def run_server():
            server_address = ('', 8000)
            httpd = HTTPServer(server_address, lambda *args, **kwargs: WebViewer(self, *args, **kwargs))
            print("ğŸŒ ì›¹ ëŒ€ì‹œë³´ë“œ: http://localhost:8000/")
            httpd.serve_forever()

        self.web_thread = threading.Thread(target=run_server, daemon=True)
        self.web_thread.start()

        self.get_logger().info("ğŸš¦ Traffic Light Detector with GStreamer Display Started!")

    def image_callback(self, msg):
        """ì¹´ë©”ë¼ ì´ë¯¸ì§€ ì²˜ë¦¬ ì½œë°±"""
        try:
            # ì´ë¯¸ì§€ ë””ì½”ë”©
            np_arr = np.frombuffer(msg.data, np.uint8)
            image = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
            
            if image is None:
                return

            # ì‹ í˜¸ë“± ê²€ì¶œ ë° ì´ë¯¸ì§€ ì²˜ë¦¬
            processed_image = self.process_image(image)
            
            # FPS ê³„ì‚°
            self.frame_count += 1
            current_time = time.time()
            if current_time - self.last_time >= 1.0:
                self.fps = self.frame_count / (current_time - self.last_time)
                self.frame_count = 0
                self.last_time = current_time

            # ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ì €ì¥ (ì›¹ê³¼ gstreamer ëª¨ë‘ ì‚¬ìš©)
            ret, jpeg = cv2.imencode('.jpg', processed_image, [cv2.IMWRITE_JPEG_QUALITY, 85])
            if ret:
                self.last_image = jpeg.tobytes()
                self.last_processed_image = processed_image.copy()

            # ì½˜ì†” ì¶œë ¥
            self.print_detection_status()

        except Exception as e:
            self.get_logger().error(f'ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}')

    def process_image(self, image):
        """ì´ë¯¸ì§€ ì²˜ë¦¬ ë° ì‹ í˜¸ë“± ê²€ì¶œ"""
        processed = image.copy()
        height, width = image.shape[:2]
        
        # ìƒíƒœ í—¤ë” ê·¸ë¦¬ê¸°
        self.draw_status_overlay(processed)
        
        # ì‹ í˜¸ë“± ê²€ì¶œ
        self.detected_color, self.confidence = self.detect_traffic_light(image, processed)
        
        # ê²€ì¶œ ê²°ê³¼ì— ë”°ë¥¸ ìƒíƒœ ì—…ë°ì´íŠ¸
        self.update_detection_state()
        
        return processed

    def draw_status_overlay(self, image):
        """ìƒíƒœ ì •ë³´ ì˜¤ë²„ë ˆì´"""
        height, width = image.shape[:2]
        
        # ë°˜íˆ¬ëª… ë°°ê²½
        overlay = image.copy()
        cv2.rectangle(overlay, (0, 0), (width, 120), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.75, image, 0.25, 0, image)
        
        # ìƒíƒœì— ë”°ë¥¸ ìƒ‰ìƒ
        if self.detected_color == "GREEN":
            status_color = (0, 255, 0)
            status_text = "ğŸŸ¢ GREEN LIGHT DETECTED!"
        elif self.detected_color == "RED":
            status_color = (0, 0, 255)
            status_text = "ğŸ”´ RED LIGHT DETECTED"
        elif self.detected_color == "ORANGE":
            status_color = (0, 165, 255)
            status_text = "ğŸŸ  ORANGE LIGHT DETECTED"
        else:
            status_color = (128, 128, 128)
            status_text = "âš« NO TRAFFIC LIGHT"
        
        # í…ìŠ¤íŠ¸ ì •ë³´
        cv2.putText(image, f'ğŸš¦ Traffic Light Detection | {status_text}', 
                   (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, status_color, 2)
        cv2.putText(image, f'Mode: {self.current_mode.value} | FPS: {self.fps:.1f}', 
                   (10, 55), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
        cv2.putText(image, f'Confidence: {self.confidence:.1f}% | Consecutive Green: {self.consecutive_green_frames}', 
                   (10, 85), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
        
        # ì‹ í˜¸ë“± LED ì‹œë®¬ë ˆì´ì…˜ (ìš°ìƒë‹¨)
        self.draw_traffic_light_led(image)

    def draw_traffic_light_led(self, image):
        """ì‹ í˜¸ë“± LED ì‹œë®¬ë ˆì´ì…˜ ê·¸ë¦¬ê¸°"""
        height, width = image.shape[:2]
        led_size = 25
        led_x = width - 60
        spacing = 40
        
        # ë¹¨ê°„ë¶ˆ
        red_color = (0, 0, 255) if self.detected_color == "RED" else (50, 0, 0)
        cv2.circle(image, (led_x, 30), led_size, red_color, -1)
        cv2.circle(image, (led_x, 30), led_size, (255, 255, 255), 2)
        
        # ì£¼í™©ë¶ˆ
        orange_color = (0, 165, 255) if self.detected_color == "ORANGE" else (50, 50, 0)
        cv2.circle(image, (led_x, 30 + spacing), led_size, orange_color, -1)
        cv2.circle(image, (led_x, 30 + spacing), led_size, (255, 255, 255), 2)
        
        # ì´ˆë¡ë¶ˆ
        green_color = (0, 255, 0) if self.detected_color == "GREEN" else (0, 50, 0)
        cv2.circle(image, (led_x, 30 + spacing * 2), led_size, green_color, -1)
        cv2.circle(image, (led_x, 30 + spacing * 2), led_size, (255, 255, 255), 2)

    def detect_traffic_light(self, image, processed_image):
        """ê°œì„ ëœ ì‹ í˜¸ë“± ê²€ì¶œ"""
        height, width, _ = image.shape
        
        # ROI ì„¤ì • (í™”ë©´ ìƒë‹¨ 1/3)
        roi = image[0:int(height / 3), 0:width]
        hsv = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
        
        # ìƒ‰ìƒë³„ HSV ë²”ìœ„ (ë” ì •í™•í•˜ê²Œ ì¡°ì •)
        color_ranges = {
            "RED": [
                (np.array([0, 120, 120]), np.array([10, 255, 255])),     # ë¹¨ê°• 1
                (np.array([170, 120, 120]), np.array([180, 255, 255]))   # ë¹¨ê°• 2
            ],
            "ORANGE": [
                (np.array([10, 150, 150]), np.array([25, 255, 255]))     # ì£¼í™©
            ],
            "GREEN": [
                (np.array([40, 120, 120]), np.array([80, 255, 255])),    # ê¸°ë³¸ ë…¹ìƒ‰
                (np.array([50, 150, 180]), np.array([70, 255, 255]))     # LED ë…¹ìƒ‰
            ]
        }
        
        best_detection = {"color": "NONE", "confidence": 0.0, "area": 0}
        
        for color, ranges in color_ranges.items():
            # ì—¬ëŸ¬ ë²”ìœ„ ë§ˆìŠ¤í¬ ê²°í•©
            combined_mask = None
            for lower, upper in ranges:
                mask = cv2.inRange(hsv, lower, upper)
                if combined_mask is None:
                    combined_mask = mask
                else:
                    combined_mask = cv2.bitwise_or(combined_mask, mask)
            
            # ë…¸ì´ì¦ˆ ì œê±°
            kernel = np.ones((5, 5), np.uint8)
            combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_OPEN, kernel, iterations=2)
            combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_CLOSE, kernel, iterations=1)
            
            # ì»¨íˆ¬ì–´ ì°¾ê¸°
            contours, _ = cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            for contour in contours:
                area = cv2.contourArea(contour)
                if area > 150:  # ìµœì†Œ ë©´ì 
                    x, y, w, h = cv2.boundingRect(contour)
                    aspect_ratio = float(w) / h
                    
                    # ì›í˜•ë„ ê³„ì‚°
                    perimeter = cv2.arcLength(contour, True)
                    if perimeter > 0:
                        circularity = 4 * math.pi * area / (perimeter * perimeter)
                    else:
                        circularity = 0
                    
                    # ì‹ í˜¸ë“± ì¡°ê±´ ê²€ì‚¬
                    if (0.5 < aspect_ratio < 2.0 and    # ì›í˜•/ì •ì‚¬ê°í˜•
                        circularity > 0.3 and           # ì›í˜•ì— ê°€ê¹Œì›€
                        area > 200):                     # ì¶©ë¶„í•œ ë©´ì 
                        
                        # ë°ê¸° í™•ì¸
                        roi_brightness = cv2.mean(roi[y:y+h, x:x+w])[0]
                        confidence = area * circularity * (roi_brightness / 255.0) * 0.1
                        
                        # ê°€ì¥ ì¢‹ì€ ê²€ì¶œ ê²°ê³¼ ì—…ë°ì´íŠ¸
                        if confidence > best_detection["confidence"]:
                            best_detection = {
                                "color": color,
                                "confidence": confidence,
                                "area": area,
                                "bbox": (x, y, w, h),
                                "brightness": roi_brightness
                            }
        
        # ê²€ì¶œ ê²°ê³¼ ì‹œê°í™”
        if best_detection["color"] != "NONE":
            x, y, w, h = best_detection["bbox"]
            
            # ìƒ‰ìƒì— ë”°ë¥¸ í‘œì‹œ
            if best_detection["color"] == "RED":
                color_bgr = (0, 0, 255)
                text = "RED LIGHT"
            elif best_detection["color"] == "ORANGE":
                color_bgr = (0, 165, 255)
                text = "ORANGE LIGHT"
            elif best_detection["color"] == "GREEN":
                color_bgr = (0, 255, 0)
                text = "GREEN LIGHT"
            
            # ì‚¬ê°í˜•ê³¼ í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
            cv2.rectangle(processed_image, (x, y), (x + w, y + h), color_bgr, 3)
            cv2.putText(processed_image, text, (x, y - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color_bgr, 2)
            
            # ì‹ ë¢°ë„ í‘œì‹œ
            cv2.putText(processed_image, f'Conf: {best_detection["confidence"]:.1f}', 
                       (x, y + h + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color_bgr, 1)
            
            # ì¤‘ì‹¬ì  í‘œì‹œ
            center_x, center_y = x + w//2, y + h//2
            cv2.circle(processed_image, (center_x, center_y), 5, color_bgr, -1)
        
        return best_detection["color"], best_detection["confidence"]

    def update_detection_state(self):
        """ê²€ì¶œ ìƒíƒœ ì—…ë°ì´íŠ¸"""
        if self.detected_color == "GREEN":
            self.consecutive_green_frames += 1
            if self.consecutive_green_frames >= 5:  # 5í”„ë ˆì„ ì—°ì† ê²€ì¶œ
                self.green_detected = True
                self.current_mode = DriveMode.RUBBERCON_AVOIDANCE
        else:
            self.consecutive_green_frames = max(0, self.consecutive_green_frames - 1)
            if self.consecutive_green_frames == 0:
                self.green_detected = False
        
        # ë‹¤ë¥¸ ìƒ‰ìƒ ê²€ì¶œ
        self.red_detected = (self.detected_color == "RED")
        self.orange_detected = (self.detected_color == "ORANGE")

    def display_loop(self):
        """GStreamer ì°½ í‘œì‹œ ë£¨í”„"""
        self.get_logger().info("ğŸ–¼ï¸ OpenCV ë””ìŠ¤í”Œë ˆì´ ì°½ ì‹œì‘...")
        
        while rclpy.ok():
            try:
                if self.last_processed_image is not None:
                    # ì°½ í¬ê¸° ì¡°ì •
                    display_image = cv2.resize(self.last_processed_image, (1024, 768))
                    cv2.imshow('ğŸš¦ Traffic Light Detection', display_image)
                    
                    key = cv2.waitKey(1) & 0xFF
                    if key == ord('q') or key == 27:  # 'q' ë˜ëŠ” ESC
                        break
                    elif key == ord('r'):  # ë¦¬ì…‹
                        self.reset_detection()
                        
                time.sleep(0.033)  # ~30 FPS
                
            except Exception as e:
                self.get_logger().error(f'ë””ìŠ¤í”Œë ˆì´ ì˜¤ë¥˜: {e}')
                break
        
        cv2.destroyAllWindows()

    def reset_detection(self):
        """ê²€ì¶œ ìƒíƒœ ë¦¬ì…‹"""
        self.detected_color = "NONE"
        self.confidence = 0.0
        self.consecutive_green_frames = 0
        self.green_detected = False
        self.red_detected = False
        self.orange_detected = False
        self.current_mode = DriveMode.WAITING_FOR_GREEN
        self.get_logger().info("ğŸ”„ ê²€ì¶œ ìƒíƒœ ë¦¬ì…‹!")

    def print_detection_status(self):
        """ê²€ì¶œ ìƒíƒœ ì½˜ì†” ì¶œë ¥ (5ì´ˆë§ˆë‹¤)"""
        if not hasattr(self, 'last_print_time'):
            self.last_print_time = 0
        
        current_time = time.time()
        if current_time - self.last_print_time >= 5.0:
            if self.detected_color == "RED":
                self.get_logger().info("ğŸ”´ ë¹¨ê°„ë¶ˆ ê°ì§€ë¨ - ëŒ€ê¸° ì¤‘...")
            elif self.detected_color == "ORANGE":
                self.get_logger().info("ğŸŸ  ì£¼í™©ë¶ˆ ê°ì§€ë¨ - ëŒ€ê¸° ì¤‘...")
            elif self.detected_color == "GREEN":
                self.get_logger().info("ğŸŸ¢ ì´ˆë¡ë¶ˆ ê°ì§€ë¨ - ì¶œë°œ ì¤€ë¹„!")
            else:
                self.get_logger().info("âš« ì‹ í˜¸ë“±ì„ ì°¾ê³  ìˆìŠµë‹ˆë‹¤...")
            
            self.last_print_time = current_time

    def get_stats(self):
        """ì›¹ ëŒ€ì‹œë³´ë“œìš© í†µê³„ ë°˜í™˜"""
        return {
            "current_mode": self.current_mode.value,
            "traffic_light_status": self.detected_color,
            "confidence": f"{self.confidence:.1f}",
            "fps": f"{self.fps:.1f}",
        }

def main(args=None):
    rclpy.init(args=args)
    
    try:
        detector = TrafficLightDetector()
        
        print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘        ğŸš¦ TRAFFIC LIGHT DETECTOR               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  â€¢ OpenCV ì°½ê³¼ ì›¹ ëŒ€ì‹œë³´ë“œì—ì„œ ê²°ê³¼ í™•ì¸       â•‘
â•‘  â€¢ 'q' ë˜ëŠ” ESC: ì¢…ë£Œ                         â•‘  
â•‘  â€¢ 'r': ê²€ì¶œ ìƒíƒœ ë¦¬ì…‹                        â•‘
â•‘  â€¢ ì›¹ ëŒ€ì‹œë³´ë“œ: http://localhost:8000/        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        """)
        
        rclpy.spin(detector)
        
    except KeyboardInterrupt:
        print("\nğŸ Traffic Light Detector ì¢…ë£Œ!")
    finally:
        if 'detector' in locals():
            detector.destroy_node()
        rclpy.shutdown()
        cv2.destroyAllWindows()

if __name__ == '__main__':
    main()
