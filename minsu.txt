#!/usr/bin/env python3

import rclpy
from rclpy.node import Node
from rclpy.qos import QoSProfile, ReliabilityPolicy
from sensor_msgs.msg import CompressedImage, LaserScan
from geometry_msgs.msg import Twist
import cv2
import numpy as np
import threading
import time
import socket
import math
import json
from http.server import BaseHTTPRequestHandler, HTTPServer
from enum import Enum

# QOS 프로파일 설정
qos_profile = QoSProfile(depth=10)
qos_profile.reliability = ReliabilityPolicy.BEST_EFFORT

# 주행 모드를 정의하는 열거형
class DriveMode(Enum):
    TRAFFIC_LIGHT_WAIT = "TRAFFIC_LIGHT_WAIT"
    RUBBERCON_AVOIDANCE = "RUBBERCON_AVOID"
    LANE_FOLLOWING = "LANE_FOLLOW"
    OBSTACLE_CAR_AVOIDANCE = "OBSTACLE_CAR_AVOID"
    EMERGENCY_STOP = "EMERGENCY_STOP"

# 웹 대시보드를 위한 HTTP 서버 핸들러
class WebViewer(BaseHTTPRequestHandler):
    def __init__(self, autoracer_node, *args, **kwargs):
        self.autoracer = autoracer_node
        super().__init__(*args, **kwargs)

    def do_GET(self):
        if self.path == '/':
            self.send_response(200)
            self.send_header('Content-Type', 'text/html')
            self.end_headers()
            html = """
            <html>
            <head>
                <title>🏁 Autoracer 2025 Contest - Enhanced Driving Logic</title>
                <style>
                    body { background: linear-gradient(135deg, #1e1e1e, #2d2d30); color: #fff; font-family: 'Segoe UI', Arial; margin: 0; padding: 20px; }
                    .container { display: flex; gap: 20px; max-width: 1400px; margin: 0 auto; }
                    .panel { background: rgba(255,255,255,0.1); border-radius: 12px; padding: 20px; backdrop-filter: blur(10px); }
                    .status-card { background: rgba(0,255,0,0.1); border-left: 4px solid #00ff00; margin: 10px 0; padding: 15px; border-radius: 8px; }
                    .metric { display: flex; justify-content: space-between; margin: 8px 0; }
                    .metric-value { font-weight: bold; color: #00ff88; }
                    h1 { text-align: center; color: #00ff88; text-shadow: 0 0 20px #00ff88; }
                    h3 { color: #00ccff; margin-top: 0; }
                </style>
            </head>
            <body>
                <h1>🏆 Autoracer 2025 Contest - Enhanced Driving Logic</h1>
                <div class="container">
                    <div class="panel" style="flex: 2;">
                        <h3>📹 Live Camera Feed</h3>
                        <img src="/stream.mjpg" width="800" height="600" style="border: 2px solid #444; border-radius: 8px; width: 100%; max-width: 800px;">
                    </div>
                    <div class="panel" style="flex: 1;">
                        <h3>🎯 Mission Control</h3>
                        <div class="status-card">
                            <div class="metric"><span>Current Mode:</span><span id="mode" class="metric-value">Loading...</span></div>
                            <div class="metric"><span>Lane Status:</span><span id="lane" class="metric-value">Detecting...</span></div>
                            <div class="metric"><span>Obstacle Car:</span><span id="obstacle_car" class="metric-value">None...</span></div>
                        </div>
                        <h3>📊 Vehicle Telemetry</h3>
                        <div class="status-card">
                            <div class="metric"><span>FPS:</span><span id="camera_fps" class="metric-value">0</span></div>
                            <div class="metric"><span>Lidar (Front):</span><span id="lidar_dist" class="metric-value">N/A</span> m</div>
                            <div class="metric"><span>Speed:</span><span id="speed" class="metric-value">0</span> m/s</div>
                            <div class="metric"><span>Steering:</span><span id="steering" class="metric-value">0</span>°</div>
                        </div>
                    </div>
                </div>
                <script>
                setInterval(() => {
                    fetch('/stats')
                    .then(r => r.json())
                    .then(data => {
                        document.getElementById('mode').textContent = data.current_mode;
                        document.getElementById('lane').textContent = data.lane_status;
                        document.getElementById('obstacle_car').textContent = data.obstacle_car_status;
                        document.getElementById('camera_fps').textContent = data.camera_fps;
                        document.getElementById('lidar_dist').textContent = data.lidar_distance;
                        document.getElementById('speed').textContent = data.speed;
                        document.getElementById('steering').textContent = data.steering_angle;
                    }).catch(e => console.log('Stats error:', e));
                }, 500);
                </script>
            </body>
            </html>
            """
            self.wfile.write(html.encode())
            
        elif self.path == '/stream.mjpg':
            self.send_response(200)
            self.send_header('Content-Type', 'multipart/x-mixed-replace; boundary=frame')
            self.end_headers()
            try:
                while True:
                    frame = self.autoracer.get_processed_frame()
                    if frame is not None:
                        _, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 85])
                        self.wfile.write(b'--frame\r\n')
                        self.send_header('Content-Type', 'image/jpeg')
                        self.send_header('Content-Length', str(len(buffer)))
                        self.end_headers()
                        self.wfile.write(buffer)
                        self.wfile.write(b'\r\n')
                    time.sleep(0.033)
            except Exception as e:
                self.autoracer.get_logger().error(f'Streaming error: {e}')
                
        elif self.path == '/stats':
            self.send_response(200)
            self.send_header('Content-Type', 'application/json')
            self.end_headers()
            stats = self.autoracer.get_stats()
            self.wfile.write(json.dumps(stats).encode())
        else:
            self.send_response(404)
            self.end_headers()

# 메인 자율주행 노드 클래스
class Autoracer(Node):
    def __init__(self):
        super().__init__('Autoracer')
        
        # 센서 데이터 및 동기화 관련 변수
        self.current_image = None
        self.processed_frame = None
        self.lidar_data = None
        self.image_lock = threading.Lock()
        
        # 주행 상태 관리
        self.current_mode = DriveMode.TRAFFIC_LIGHT_WAIT
        
        # 제어 관련 변수
        self.current_speed = 0.0
        self.current_steering = 0.0
        self.target_speed = 0.0
        self.target_steering = 0.0
        
        # PID 제어 관련 변수
        self.prev_error = 0.0
        self.integral_error = 0.0
        
        # 신호등 미션 관련 변수
        self.traffic_light_state = "SEARCHING"
        self.green_light_detected_time = None
        
        # 장애물 차량 회피 미션 관련 변수
        self.obstacle_car_position = None
        self.obstacle_avoidance_start_time = None
        
        # 라바콘 회피 미션 관련 변수
        self.rubbercon_status = "SEARCHING"
        self.no_rubbercon_frames = 0
        
        # 성능 및 통계 데이터
        self.camera_fps = 0
        self.last_camera_time = time.time()
        
        # Bird's Eye View(BEV) 변환 행렬
        self.bev_matrix = None
        self.inv_bev_matrix = None
        self.setup_bev_transform()
        
        # --- 차선 추종 안정성 강화를 위한 변수 ---
        self.left_fit = None
        self.right_fit = None
        self.lane_lost_counter = 0

        # ROS2 구독자 및 발행자 설정
        self.image_sub = self.create_subscription(CompressedImage, '/image_raw/compressed', self.image_callback, 10)
        self.lidar_sub = self.create_subscription(LaserScan, '/scan', self.lidar_callback, qos_profile)
        self.cmd_pub = self.create_publisher(Twist, '/cmd_vel', 10)
        
        # 웹 서버 시작
        self.start_web_server()
        
        # 제어 루프 타이머 (20Hz)
        self.control_timer = self.create_timer(0.05, self.control_loop)
        
        self.get_logger().info('✅ Autoracer Enhanced Driving Node has been started.')

    def setup_bev_transform(self):
        """Bird's Eye View 변환 행렬을 설정합니다."""
        src_points = np.float32([[80, 480], [560, 480], [240, 280], [400, 280]])
        dst_points = np.float32([[150, 480], [490, 480], [150, 0], [490, 0]])
        self.bev_matrix = cv2.getPerspectiveTransform(src_points, dst_points)
        self.inv_bev_matrix = cv2.getPerspectiveTransform(dst_points, src_points)

    def get_ip_address(self):
        """현재 장비의 IP 주소를 반환합니다."""
        try:
            s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            s.connect(("8.8.8.8", 80))
            ip = s.getsockname()[0]
            s.close()
            return ip
        except Exception:
            return "localhost"

    def start_web_server(self):
        """웹 대시보드 서버를 별도의 스레드에서 실행합니다."""
        def run_server():
            port = 8080
            while port < 8090:
                try:
                    server_address = ('0.0.0.0', port)
                    httpd = HTTPServer(server_address, lambda *args, **kwargs: WebViewer(self, *args, **kwargs))
                    self.get_logger().info(f'🌐 Web server is running on http://{self.get_ip_address()}:{port}/')
                    httpd.serve_forever()
                    break
                except OSError:
                    port += 1
        
        server_thread = threading.Thread(target=run_server, daemon=True)
        server_thread.start()

    def image_callback(self, msg):
        """카메라 이미지를 수신하고 처리 파이프라인을 시작합니다."""
        try:
            np_arr = np.frombuffer(msg.data, np.uint8)
            image = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
            
            with self.image_lock:
                self.current_image = image.copy()
            
            self.process_image(image)
            
            # FPS 계산
            current_time = time.time()
            self.camera_fps = round(1.0 / (current_time - self.last_camera_time))
            self.last_camera_time = current_time
                
        except Exception as e:
            self.get_logger().error(f'Image processing error: {e}')

    def process_image(self, image):
        """현재 주행 모드에 따라 이미지 처리를 분기합니다."""
        processed = image.copy()
        
        if self.current_mode == DriveMode.TRAFFIC_LIGHT_WAIT:
            self.detect_traffic_light(processed)
        elif self.current_mode == DriveMode.RUBBERCON_AVOIDANCE:
            self.detect_and_avoid_rubbercon(processed)
        elif self.current_mode == DriveMode.LANE_FOLLOWING:
            self.follow_lane_advanced(processed)
            if self.detect_obstacle_car(processed):
                self.current_mode = DriveMode.OBSTACLE_CAR_AVOIDANCE
                self.get_logger().info('🚗 Obstacle Car Detected! Switching to Avoidance Mode.')
        elif self.current_mode == DriveMode.OBSTACLE_CAR_AVOIDANCE:
            self.avoid_obstacle_car(processed)
        
        if self.lidar_data:
            self.draw_lidar_overlay(processed)
            
        self.draw_status_header(processed)

        with self.image_lock:
            self.processed_frame = processed.copy()

    def detect_traffic_light(self, image):
        """녹색 신호등을 감지하여 다음 미션으로 전환합니다."""
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        lower_green = np.array([35, 80, 80])
        upper_green = np.array([85, 255, 255])
        green_mask = cv2.inRange(hsv, lower_green, upper_green)
        
        contours, _ = cv2.findContours(green_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        detected = False
        for contour in contours:
            area = cv2.contourArea(contour)
            if area > 100:
                x, y, w, h = cv2.boundingRect(contour)
                cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)
                self.traffic_light_state = "GREEN"
                detected = True
                break
        
        if detected:
            if self.green_light_detected_time is None:
                self.green_light_detected_time = time.time()
            elif time.time() - self.green_light_detected_time > 1.0: # 1초간 녹색불 유지 시
                self.get_logger().info('🚦 Traffic light passed! Moving to rubbercon avoidance.')
                self.current_mode = DriveMode.RUBBERCON_AVOIDANCE
        else:
            self.traffic_light_state = "RED_OR_SEARCHING"
            self.green_light_detected_time = None
            self.target_speed = 0.0

    def detect_and_avoid_rubbercon(self, image):
        """라바콘을 감지하고 회피 주행합니다."""
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        lower_orange = np.array([5, 100, 100])
        upper_orange = np.array([25, 255, 255])
        orange_mask = cv2.inRange(hsv, lower_orange, upper_orange)

        height, width = image.shape[:2]
        contours, _ = cv2.findContours(orange_mask[height//2:, :], cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        if contours:
            self.no_rubbercon_frames = 0
            self.rubbercon_status = f"DETECTED: {len(contours)}"
            
            left_cones = [c for c in contours if cv2.boundingRect(c)[0] < width // 2]
            right_cones = [c for c in contours if cv2.boundingRect(c)[0] > width // 2]
            
            target_x = width // 2
            if left_cones and right_cones:
                left_most_c = max(left_cones, key=lambda c: cv2.boundingRect(c)[0])
                right_most_c = min(right_cones, key=lambda c: cv2.boundingRect(c)[0])
                target_x = (cv2.boundingRect(left_most_c)[0] + cv2.boundingRect(right_most_c)[0]) // 2
            elif left_cones:
                left_most_c = max(left_cones, key=lambda c: cv2.boundingRect(c)[0])
                target_x = cv2.boundingRect(left_most_c)[0] + 150
            elif right_cones:
                right_most_c = min(right_cones, key=lambda c: cv2.boundingRect(c)[0])
                target_x = cv2.boundingRect(right_most_c)[0] - 150

            error = target_x - width // 2
            self.target_steering = np.clip(error * 0.003, -0.7, 0.7)
            self.target_speed = 0.3
        else:
            self.no_rubbercon_frames += 1
            if self.no_rubbercon_frames > 10:
                self.get_logger().info('✅ Rubbercon mission passed! Switching to lane following.')
                self.current_mode = DriveMode.LANE_FOLLOWING

    def follow_lane_advanced(self, image):
        """[개선된 로직] 안정성과 곡선 주행 성능이 향상된 차선 추종"""
        bev_image = cv2.warpPerspective(image, self.bev_matrix, (640, 480))
        
        # 흑백 이미지와 컬러 이미지를 모두 사용하여 차선 마스크 생성
        gray_bev = cv2.cvtColor(bev_image, cv2.COLOR_BGR2GRAY)
        adaptive_thresh = cv2.adaptiveThreshold(gray_bev, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 15, -5)
        
        hsv_bev = cv2.cvtColor(bev_image, cv2.COLOR_BGR2HSV)
        lower_white = np.array([0, 0, 180])
        upper_white = np.array([180, 40, 255])
        white_mask = cv2.inRange(hsv_bev, lower_white, upper_white)
        
        lower_yellow = np.array([20, 80, 80])
        upper_yellow = np.array([35, 255, 255])
        yellow_mask = cv2.inRange(hsv_bev, lower_yellow, upper_yellow)
        
        lane_mask = cv2.bitwise_or(cv2.bitwise_or(white_mask, yellow_mask), adaptive_thresh)

        # 마스크로부터 차선 피팅
        self.left_fit, self.right_fit, success = self.find_lane_lines_from_mask(lane_mask)

        if success:
            self.lane_lost_counter = 0
            self.calculate_advanced_steering(image.shape)
        else:
            self.lane_lost_counter += 1
            if self.lane_lost_counter > 10:
                self.target_speed = 0.2
                self.target_steering = 0.0
                self.left_fit, self.right_fit = None, None

        self.draw_lane_overlay(image, bev_image, lane_mask)

    def find_lane_lines_from_mask(self, mask):
        """이전 프레임 정보를 활용하여 효율적으로 차선을 찾고 피팅"""
        if self.left_fit is not None and self.right_fit is not None:
            left_fit, right_fit, success = self.search_around_poly(mask)
            if success:
                return left_fit, right_fit, True
        
        return self.blind_search_lanes(mask)

    def blind_search_lanes(self, mask):
        """슬라이딩 윈도우 방식으로 차선 전체를 탐색"""
        height, width = mask.shape
        histogram = np.sum(mask[height//2:, :], axis=0)
        midpoint = width // 2
        left_base = np.argmax(histogram[:midpoint])
        right_base = np.argmax(histogram[midpoint:]) + midpoint

        nwindows = 9
        window_height = height // nwindows
        margin, minpix = 50, 50

        nonzero = mask.nonzero()
        nonzeroy, nonzerox = np.array(nonzero[0]), np.array(nonzero[1])
        
        left_lane_inds, right_lane_inds = [], []
        leftx_current, rightx_current = left_base, right_base

        for window in range(nwindows):
            win_y_low = height - (window + 1) * window_height
            win_y_high = height - window * window_height
            win_xleft_low, win_xleft_high = leftx_current - margin, leftx_current + margin
            win_xright_low, win_xright_high = rightx_current - margin, rightx_current + margin

            good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]
            good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]
            
            left_lane_inds.append(good_left_inds)
            right_lane_inds.append(good_right_inds)

            if len(good_left_inds) > minpix:
                leftx_current = int(np.mean(nonzerox[good_left_inds]))
            if len(good_right_inds) > minpix:
                rightx_current = int(np.mean(nonzerox[good_right_inds]))

        left_lane_inds = np.concatenate(left_lane_inds)
        right_lane_inds = np.concatenate(right_lane_inds)

        leftx, lefty = nonzerox[left_lane_inds], nonzeroy[left_lane_inds]
        rightx, righty = nonzerox[right_lane_inds], nonzeroy[right_lane_inds]

        left_fit, right_fit = None, None
        if len(leftx) > 100: left_fit = np.polyfit(lefty, leftx, 2)
        if len(rightx) > 100: right_fit = np.polyfit(righty, rightx, 2)

        # 차선 유효성 검사
        if left_fit is not None and right_fit is not None:
            y_eval = height - 1
            lane_width = (right_fit[0]*y_eval**2 + right_fit[1]*y_eval + right_fit[2]) - (left_fit[0]*y_eval**2 + left_fit[1]*y_eval + left_fit[2])
            if not (150 < lane_width < 450):
                return None, None, False
        
        return left_fit, right_fit, (left_fit is not None or right_fit is not None)

    def search_around_poly(self, mask):
        """이전 프레임의 차선 주변에서 빠르게 탐색"""
        margin = 50
        nonzero = mask.nonzero()
        nonzeroy, nonzerox = np.array(nonzero[0]), np.array(nonzero[1])
        
        left_lane_inds = ((nonzerox > (self.left_fit[0]*(nonzeroy**2) + self.left_fit[1]*nonzeroy + self.left_fit[2] - margin)) & (nonzerox < (self.left_fit[0]*(nonzeroy**2) + self.left_fit[1]*nonzeroy + self.left_fit[2] + margin)))
        right_lane_inds = ((nonzerox > (self.right_fit[0]*(nonzeroy**2) + self.right_fit[1]*nonzeroy + self.right_fit[2] - margin)) & (nonzerox < (self.right_fit[0]*(nonzeroy**2) + self.right_fit[1]*nonzeroy + self.right_fit[2] + margin)))
        
        leftx, lefty = nonzerox[left_lane_inds], nonzeroy[left_lane_inds]
        rightx, righty = nonzerox[right_lane_inds], nonzeroy[right_lane_inds]

        if len(leftx) < 100 or len(rightx) < 100: return None, None, False

        left_fit, right_fit = np.polyfit(lefty, leftx, 2), np.polyfit(righty, rightx, 2)
        
        y_eval = mask.shape[0] - 1
        lane_width = (right_fit[0]*y_eval**2 + right_fit[1]*y_eval + right_fit[2]) - (left_fit[0]*y_eval**2 + left_fit[1]*y_eval + left_fit[2])
        if not (150 < lane_width < 450): return None, None, False

        return left_fit, right_fit, True

    def calculate_advanced_steering(self, shape):
        """[개선된 로직] 예측 제어 및 곡률을 고려하여 부드러운 조향각 계산"""
        height, width = shape[:2]
        y_eval = height * 0.7  # 예측 지점(Lookahead point)

        if self.left_fit is not None and self.right_fit is not None:
            left_x = self.left_fit[0]*y_eval**2 + self.left_fit[1]*y_eval + self.left_fit[2]
            right_x = self.right_fit[0]*y_eval**2 + self.right_fit[1]*y_eval + self.right_fit[2]
            lane_center = (left_x + right_x) / 2
        elif self.left_fit is not None:
            lane_center = self.left_fit[0]*y_eval**2 + self.left_fit[1]*y_eval + self.left_fit[2] + 175
        elif self.right_fit is not None:
            lane_center = self.right_fit[0]*y_eval**2 + self.right_fit[1]*y_eval + self.right_fit[2] - 175
        else: return
            
        # 위치 오차와 곡률 오차를 결합
        path_error = lane_center - (width / 2)
        curvature = (self.left_fit[0] + self.right_fit[0]) / 2 if self.left_fit is not None and self.right_fit is not None else 0
        curvature_error = curvature * 2000
        total_error = path_error + curvature_error

        # PID 제어
        kp, ki, kd = 0.0025, 0.00001, 0.003
        p_term = kp * total_error
        self.integral_error = np.clip(self.integral_error + total_error, -1000, 1000)
        i_term = ki * self.integral_error
        d_term = kd * (total_error - self.prev_error)
        self.prev_error = total_error
        
        steering = p_term + i_term + d_term
        
        # 속도에 따른 조향 민감도 조절
        speed_factor = max(0.5, 1.0 - (self.current_speed / 0.5))
        self.target_steering = np.clip(steering * speed_factor, -0.7, 0.7)
        self.target_speed = max(0.2, 0.4 - abs(self.target_steering) * 0.2)

    def detect_obstacle_car(self, image):
        """장애물 차량을 감지합니다."""
        height, width = image.shape[:2]
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        
        lower_dark = np.array([0, 0, 0])
        upper_dark = np.array([180, 255, 80])
        dark_mask = cv2.inRange(hsv, lower_dark, upper_dark)
        
        roi = dark_mask[height//3:height*3//4, width//4:width*3//4]
        contours, _ = cv2.findContours(roi, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        for contour in contours:
            if cv2.contourArea(contour) > 1000:
                self.obstacle_car_position = "CENTER"
                return True
        
        self.obstacle_car_position = None
        return False

    def avoid_obstacle_car(self, image):
        """장애물 차량을 회피 주행합니다."""
        if self.obstacle_avoidance_start_time is None:
            self.obstacle_avoidance_start_time = time.time()
            self.get_logger().info('Executing obstacle avoidance maneuver.')
        
        self.target_steering = -0.6 # 왼쪽으로 회피
        self.target_speed = 0.25

        if time.time() - self.obstacle_avoidance_start_time > 3.0:
            self.get_logger().info('✅ Obstacle avoidance complete. Resuming lane following.')
            self.current_mode = DriveMode.LANE_FOLLOWING
            self.obstacle_avoidance_start_time = None

    def draw_lane_overlay(self, image, bev_image, lane_mask):
        """차선 검출 결과를 시각화하여 이미지에 오버레이합니다."""
        lane_img = np.zeros_like(bev_image)
        plot_y = np.linspace(0, bev_image.shape[0]-1, bev_image.shape[0])

        if self.left_fit is not None and self.right_fit is not None:
            left_fit_x = self.left_fit[0]*plot_y**2 + self.left_fit[1]*plot_y + self.left_fit[2]
            right_fit_x = self.right_fit[0]*plot_y**2 + self.right_fit[1]*plot_y + self.right_fit[2]
            pts_left = np.array([np.transpose(np.vstack([left_fit_x, plot_y]))])
            pts_right = np.array([np.transpose(np.vstack([right_fit_x, plot_y]))])
            pts = np.hstack((pts_left, pts_right[:, ::-1, :]))
            cv2.fillPoly(lane_img, np.int_([pts]), (0, 255, 0))
        
        warped_back = cv2.warpPerspective(lane_img, self.inv_bev_matrix, (image.shape[1], image.shape[0]))
        result = cv2.addWeighted(image, 1, warped_back, 0.3, 0)
        np.copyto(image, result)

    def draw_lidar_overlay(self, image):
        """라이다 데이터를 이미지에 시각화합니다."""
        height, width = image.shape[:2]
        center_x, center_y = width // 2, height
        for i, dist in enumerate(self.lidar_data):
            if not (math.isinf(dist) or math.isnan(dist) or dist > 2.0):
                angle = (i / len(self.lidar_data) - 0.5) * math.pi * 2
                x = int(center_x + math.sin(angle) * dist * 150)
                y = int(center_y - math.cos(angle) * dist * 150)
                if 0 <= x < width and 0 <= y < height:
                    color = (0, 0, 255) if dist < 0.5 else (0, 255, 255)
                    cv2.circle(image, (x, y), 3, color, -1)

    def draw_status_header(self, image):
        """주행 상태 정보를 이미지 상단에 표시합니다."""
        overlay = image.copy()
        cv2.rectangle(overlay, (0, 0), (image.shape[1], 60), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.6, image, 0.4, 0, image)
        
        mode_text = f"Mode: {self.current_mode.value}"
        speed_text = f"Speed: {self.current_speed:.2f} m/s"
        steer_text = f"Steer: {math.degrees(self.current_steering):.1f} deg"
        
        cv2.putText(image, mode_text, (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        cv2.putText(image, speed_text, (250, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
        cv2.putText(image, steer_text, (450, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
        
        lane_status = "OK" if self.lane_lost_counter == 0 else f"LOST({self.lane_lost_counter})"
        lane_text = f"Lane: {lane_status}"
        cv2.putText(image, lane_text, (10, 45), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 1)


    def lidar_callback(self, msg):
        """라이다 데이터를 수신합니다."""
        self.lidar_data = msg.ranges

    def control_loop(self):
        """주기적으로 차량의 속도와 조향각을 발행합니다."""
        twist = Twist()
        self.current_speed = self.current_speed * 0.9 + self.target_speed * 0.1
        self.current_steering = self.current_steering * 0.9 + self.target_steering * 0.1
        twist.linear.x = self.current_speed
        twist.angular.z = self.current_steering
        self.cmd_pub.publish(twist)

    def get_processed_frame(self):
        """웹 서버로 전송할 처리된 프레임을 반환합니다."""
        with self.image_lock:
            return self.processed_frame.copy() if self.processed_frame is not None else None

    def get_stats(self):
        """웹 서버로 전송할 상태 정보를 JSON 형식으로 반환합니다."""
        min_lidar_dist = "N/A"
        if self.lidar_data and not (math.isinf(self.lidar_data[0]) or math.isnan(self.lidar_data[0])):
            min_lidar_dist = round(self.lidar_data[0], 2)
        
        return {
            "current_mode": self.current_mode.value,
            "lane_status": "OK" if self.lane_lost_counter == 0 else f"LOST({self.lane_lost_counter})",
            "obstacle_car_status": self.obstacle_car_position or "None",
            "camera_fps": self.camera_fps,
            "lidar_distance": min_lidar_dist,
            "speed": round(self.current_speed, 2),
            "steering_angle": round(math.degrees(self.current_steering), 1),
        }

def main(args=None):
    rclpy.init(args=args)
    autoracer_node = Autoracer()
    try:
        rclpy.spin(autoracer_node)
    except KeyboardInterrupt:
        autoracer_node.get_logger().info('🛑 Node stopped cleanly.')
    finally:
        autoracer_node.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    main()
